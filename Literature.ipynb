{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Literature.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjxV6KrpQZ1TDXhx1IeQ9r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mirrormouse/machine_learning/blob/main/Literature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNiQ1ZPFQWie"
      },
      "source": [
        "# 日本語の文学を機械学習して新たな文章を生成できないか？\n",
        "今回は名作を機械学習に用いて新しく「それっぽい文」を生成することを目指します。  \n",
        "markovify等のマルコフ連鎖を使ったやり方が有名な課題ではありますが、ここはあくまで「機械学習」でやってみます。  \n",
        "「とりあえずやってみて機械学習に慣れること」が目標なので、あまり難しいことは考えずにいきましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VgnRj2rMxxG"
      },
      "source": [
        "ドライブのインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI-_LXVgY3v6",
        "outputId": "a5a26a30-3c4d-4acd-a526-ec0d4605e016"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vFHLZicM9vt"
      },
      "source": [
        "形態素解析に必要なものをインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM6UyoeddCr5",
        "outputId": "bc603ab8-9cf8-441b-eabf-a41937e791f3"
      },
      "source": [
        "!pip install mecab-python3\n",
        "!pip install unidic"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mecab-python3\n",
            "  Downloading mecab_python3-1.0.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-1.0.4\n",
            "Collecting unidic\n",
            "  Downloading unidic-1.0.3.tar.gz (5.1 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from unidic) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.41.1 in /usr/local/lib/python3.7/dist-packages (from unidic) (4.62.3)\n",
            "Requirement already satisfied: wasabi<1.0.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from unidic) (0.8.2)\n",
            "Requirement already satisfied: plac<2.0.0,>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from unidic) (1.1.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.22.0->unidic) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.22.0->unidic) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.22.0->unidic) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.22.0->unidic) (2.10)\n",
            "Building wheels for collected packages: unidic\n",
            "  Building wheel for unidic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic: filename=unidic-1.0.3-py3-none-any.whl size=5506 sha256=0b456a8c39cf56bb8cbec52525a126be8367a73484b2680b9172cd9cf647532a\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/30/0b/128289fb595ef4117d2976ffdbef5069ef83be813e88caa0a6\n",
            "Successfully built unidic\n",
            "Installing collected packages: unidic\n",
            "Successfully installed unidic-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3Hb5CYFeUiL",
        "outputId": "097634fd-34dd-41d0-b0dd-af0bfeb07a4f"
      },
      "source": [
        "!python -m unidic download"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download url: https://cotonoha-dic.s3-ap-northeast-1.amazonaws.com/unidic.zip\n",
            "Dictionary version: 2.3.0+2020-10-08\n",
            "Downloading UniDic v2.3.0+2020-10-08...\n",
            "unidic.zip: 100% 608M/608M [00:30<00:00, 19.7MB/s]\n",
            "Finished download.\n",
            "Downloaded UniDic v2.3.0+2020-10-08 to /usr/local/lib/python3.7/dist-packages/unidic/dicdir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK8w1U0YM_4z"
      },
      "source": [
        "必要なものをインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLOE07xreZje"
      },
      "source": [
        "import MeCab\n",
        "import unidic\n",
        "import random\n",
        "from keras.utils.np_utils import to_categorical  \n",
        "import numpy as np\n",
        "tagger = MeCab.Tagger() "
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWT4OPLANIST"
      },
      "source": [
        "元となるデータをインストール  \n",
        "（今回は青空文庫より作・アントワーヌ・ド・サン＝テグジュペリ　訳・大久保ゆうの「星の王子様」の全文を使用しました。名作ですね）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd25ZeH7Sj7J"
      },
      "source": [
        "base='drive/MyDrive/ML/train/'\n",
        "f = open(base+'literature.txt', 'r')\n",
        "text_data = f.read()\n",
        "f.close()"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebQL2h5RN4kP"
      },
      "source": [
        "Mecabで単語に分解し、リストwordsに入れていきます。[\"\",\"ぼく\",\"が\",\"６\",\"つ\",\"の\",\"とき\"] みたいな感じ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLZYLv2cfhLk"
      },
      "source": [
        "def mecab_tokenizer(text,window):\n",
        "    parsed_text = tagger.parse(text)\n",
        "    parsed_lines = parsed_text.split(\"\\n\")\n",
        "    words=[]\n",
        "    words.append(\"\")\n",
        "    for line in parsed_lines:\n",
        "      word=line.split(\"\\t\")\n",
        "      if word[0]=='EOS':\n",
        "        break\n",
        "      words.append(word[0])\n",
        "      if word[0]==\"。\":\n",
        "        words.append(\"\")\n",
        "    return words\n",
        "#mecab_tokenizer(text_data,5)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xoF2ocGOMjb"
      },
      "source": [
        "setを使って重複を取り除き、idと単語を対応付ける辞書型リストを作ります。また、テキストを単語に分解したものをidのリストへと変換します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6BTcPnIfnlK",
        "outputId": "84f2db70-e7f9-4ae3-ca4b-71fde1c83b38"
      },
      "source": [
        "def preprocess(text_data,window=5):\n",
        "  text=mecab_tokenizer(text_data,window)\n",
        "  words=list(set(text))\n",
        "  word_dic={}\n",
        "  for id in range(len(words)):\n",
        "    word=words[id]\n",
        "    word_dic[word]=id\n",
        "  vec=[]\n",
        "  for word in text:\n",
        "    vec.append(word_dic[word])\n",
        "  return text,vec,words,word_dic\n",
        "text,vec,words,word_dic=preprocess(text_data)\n",
        "print(vec[:10])"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 815, 967, 1039, 1802, 153, 408, 1755, 2018, 1725]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lde159mAPYAw"
      },
      "source": [
        "one_hotエンコーディングする関数をつくります。  \n",
        "また、「直前の５単語」をヒントに「次の単語」を推測するモデルを作るための訓練データを作成します。  \n",
        "例）  \n",
        "x_train[0]=[\"\",\"ぼく\",\"が\",\"６\",\"つ\"]  y_train[0]=[\"の\"]  \n",
        "x_train[1]=[\"ぼく\",\"が\",\"６\",\"つ\",\"の\"]  y_train[1]=[\"とき\"]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTlmFWxtOspy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOEdK511qma_"
      },
      "source": [
        "def one_hot_encode(data,size=-1):\n",
        "  vec=np.array(data)\n",
        "  if size==-1:\n",
        "    size=vec.max()+1\n",
        "  one_hot = np.zeros((vec.size, size))\n",
        "  one_hot[np.arange(vec.size),vec] = 1\n",
        "  np_list=one_hot.astype(int)\n",
        "  res=np_list.tolist()\n",
        "  return res\n",
        "def generate_data(text_data,window=5):\n",
        "  text,vec,id2word,word2id=preprocess(text_data,window)\n",
        "  data=one_hot_encode(vec)\n",
        "  x_list=[]\n",
        "  y_list=[]\n",
        "  for id in range(window,len(data)):\n",
        "    y_list.append(vec[id])\n",
        "    x=[]\n",
        "    for i in range(id-window,id):\n",
        "      x.append(data[i])\n",
        "    x_list.append(x)\n",
        "  x_data=np.array(x_list)\n",
        "  y_data=np.array(y_list)\n",
        "  return x_data,y_data,id2word,word2id\n",
        "x_train,y_train,id2word,word2id=generate_data(text_data)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ailwWPoPnFt"
      },
      "source": [
        "データのshapeを確認します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkbKnWeKzdAW",
        "outputId": "1b8bf524-25f1-401b-e38b-e5599a224bca"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_train[0])\n",
        "print(y_train.shape)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27495, 5, 2019)\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "(27495,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpSHvNvZPuQh"
      },
      "source": [
        "最初のレイヤーのinput_shape及び最後のレイヤーの引数を、上で確認したshapeに合わせることに注意して、ニューラルネットワークのモデルを作成します。\n",
        "本当はもっと深くしたかったのですが、単語が2019種類と多くこのモデルでも学習に10分近くかかってしまったので諦めます。\n",
        "多分出現頻度の低い単語をひとまとめにするとかして単語の種類数を減らすべきだったんでしょうね。しかし今回は「とりあえずやってみる」が目標なので細かいことは無視します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26bIjJlIzTs-",
        "outputId": "fcca9ed7-4432-4143-e0a3-e2e5b5906d7d"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "model = tf.keras.Sequential(name='my_model')\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(5,2019), name='flatten_layer_1'))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(2019, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_layer_1 (Flatten)    (None, 10095)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               1292288   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 2019)              22209     \n",
            "=================================================================\n",
            "Total params: 1,315,787\n",
            "Trainable params: 1,315,787\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQP0YjMYRFEL"
      },
      "source": [
        "モデルをコンパイルします。とりあえずadamを選びました。適当です。sgdとかでもいいかも知れません。他の引数もこれ以外知らないのでこれを選んだ、という感じです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXBPr-GY2Pwx"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GvA6voeRVqo"
      },
      "source": [
        "学習します！　epochsは適当に少し大きめにしましたが、結果見る限りもう少し小さくても良かったかも。validation_splitはデータの何割を訓練ではなく評価に用いるか、です。適当に0.1とか0.2を選びます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XryFqxQQ2TwY",
        "outputId": "aa25005c-9a87-4688-c40f-763d73706b78"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=1000, epochs=100,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "22/22 [==============================] - 6s 245ms/step - loss: 7.5809 - accuracy: 0.0431 - val_loss: 7.5211 - val_accuracy: 0.0827\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 7.3127 - accuracy: 0.0352 - val_loss: 6.9241 - val_accuracy: 0.0065\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 6.2191 - accuracy: 0.0186 - val_loss: 5.4702 - val_accuracy: 0.0469\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - 5s 218ms/step - loss: 5.2788 - accuracy: 0.0529 - val_loss: 5.1464 - val_accuracy: 0.0698\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 5.0916 - accuracy: 0.0757 - val_loss: 5.0751 - val_accuracy: 0.0891\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - 5s 218ms/step - loss: 5.0087 - accuracy: 0.0762 - val_loss: 5.0353 - val_accuracy: 0.0987\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - 5s 220ms/step - loss: 4.9437 - accuracy: 0.0728 - val_loss: 5.0024 - val_accuracy: 0.0849\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - 5s 218ms/step - loss: 4.8917 - accuracy: 0.0746 - val_loss: 4.9698 - val_accuracy: 0.1007\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 4.8339 - accuracy: 0.0818 - val_loss: 4.9350 - val_accuracy: 0.0898\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - 5s 220ms/step - loss: 4.7740 - accuracy: 0.0889 - val_loss: 4.8906 - val_accuracy: 0.1397\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 4.7015 - accuracy: 0.1146 - val_loss: 4.8330 - val_accuracy: 0.1553\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - 5s 220ms/step - loss: 4.6167 - accuracy: 0.1325 - val_loss: 4.7607 - val_accuracy: 0.1762\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 4.5334 - accuracy: 0.1503 - val_loss: 4.6898 - val_accuracy: 0.1902\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 4.4542 - accuracy: 0.1649 - val_loss: 4.6228 - val_accuracy: 0.1962\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 4.3747 - accuracy: 0.1798 - val_loss: 4.5619 - val_accuracy: 0.2037\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - 5s 217ms/step - loss: 4.3017 - accuracy: 0.1911 - val_loss: 4.5021 - val_accuracy: 0.2229\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 4.2370 - accuracy: 0.2037 - val_loss: 4.4495 - val_accuracy: 0.2248\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 4.1774 - accuracy: 0.2206 - val_loss: 4.4002 - val_accuracy: 0.2420\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 4.1081 - accuracy: 0.2301 - val_loss: 4.3583 - val_accuracy: 0.2522\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 4.0476 - accuracy: 0.2399 - val_loss: 4.3195 - val_accuracy: 0.2588\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 3.9993 - accuracy: 0.2467 - val_loss: 4.2855 - val_accuracy: 0.2668\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 3.9423 - accuracy: 0.2549 - val_loss: 4.2591 - val_accuracy: 0.2699\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 3.8980 - accuracy: 0.2584 - val_loss: 4.2332 - val_accuracy: 0.2744\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 3.8631 - accuracy: 0.2642 - val_loss: 4.2130 - val_accuracy: 0.2766\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 3.8194 - accuracy: 0.2705 - val_loss: 4.1946 - val_accuracy: 0.2795\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - 5s 218ms/step - loss: 3.7782 - accuracy: 0.2736 - val_loss: 4.1827 - val_accuracy: 0.2855\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 3.7295 - accuracy: 0.2781 - val_loss: 4.1746 - val_accuracy: 0.2886\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 3.7094 - accuracy: 0.2809 - val_loss: 4.1621 - val_accuracy: 0.2921\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 3.6697 - accuracy: 0.2831 - val_loss: 4.1577 - val_accuracy: 0.2941\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 3.6390 - accuracy: 0.2901 - val_loss: 4.1445 - val_accuracy: 0.2986\n",
            "Epoch 31/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 3.6111 - accuracy: 0.2896 - val_loss: 4.1463 - val_accuracy: 0.3039\n",
            "Epoch 32/100\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 3.5799 - accuracy: 0.3004 - val_loss: 4.1441 - val_accuracy: 0.3017\n",
            "Epoch 33/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 3.5430 - accuracy: 0.3057 - val_loss: 4.1380 - val_accuracy: 0.3066\n",
            "Epoch 34/100\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 3.5252 - accuracy: 0.3061 - val_loss: 4.1444 - val_accuracy: 0.3039\n",
            "Epoch 35/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 3.4969 - accuracy: 0.3087 - val_loss: 4.1362 - val_accuracy: 0.3090\n",
            "Epoch 36/100\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 3.4823 - accuracy: 0.3123 - val_loss: 4.1374 - val_accuracy: 0.3121\n",
            "Epoch 37/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 3.4424 - accuracy: 0.3166 - val_loss: 4.1422 - val_accuracy: 0.3124\n",
            "Epoch 38/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 3.4194 - accuracy: 0.3237 - val_loss: 4.1436 - val_accuracy: 0.3157\n",
            "Epoch 39/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 3.3923 - accuracy: 0.3226 - val_loss: 4.1517 - val_accuracy: 0.3153\n",
            "Epoch 40/100\n",
            "22/22 [==============================] - 5s 220ms/step - loss: 3.3755 - accuracy: 0.3263 - val_loss: 4.1501 - val_accuracy: 0.3181\n",
            "Epoch 41/100\n",
            "22/22 [==============================] - 5s 220ms/step - loss: 3.3507 - accuracy: 0.3337 - val_loss: 4.1602 - val_accuracy: 0.3181\n",
            "Epoch 42/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 3.3271 - accuracy: 0.3337 - val_loss: 4.1613 - val_accuracy: 0.3182\n",
            "Epoch 43/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 3.3158 - accuracy: 0.3379 - val_loss: 4.1698 - val_accuracy: 0.3179\n",
            "Epoch 44/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 3.2848 - accuracy: 0.3411 - val_loss: 4.1790 - val_accuracy: 0.3190\n",
            "Epoch 45/100\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 3.2678 - accuracy: 0.3462 - val_loss: 4.1867 - val_accuracy: 0.3219\n",
            "Epoch 46/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 3.2527 - accuracy: 0.3502 - val_loss: 4.1917 - val_accuracy: 0.3193\n",
            "Epoch 47/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 3.2301 - accuracy: 0.3496 - val_loss: 4.2046 - val_accuracy: 0.3195\n",
            "Epoch 48/100\n",
            "22/22 [==============================] - 5s 220ms/step - loss: 3.2042 - accuracy: 0.3534 - val_loss: 4.2105 - val_accuracy: 0.3197\n",
            "Epoch 49/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 3.1862 - accuracy: 0.3575 - val_loss: 4.2190 - val_accuracy: 0.3177\n",
            "Epoch 50/100\n",
            "22/22 [==============================] - 5s 220ms/step - loss: 3.1751 - accuracy: 0.3583 - val_loss: 4.2261 - val_accuracy: 0.3215\n",
            "Epoch 51/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 3.1552 - accuracy: 0.3641 - val_loss: 4.2400 - val_accuracy: 0.3211\n",
            "Epoch 52/100\n",
            "22/22 [==============================] - 5s 219ms/step - loss: 3.1359 - accuracy: 0.3628 - val_loss: 4.2542 - val_accuracy: 0.3193\n",
            "Epoch 53/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 3.1110 - accuracy: 0.3720 - val_loss: 4.2546 - val_accuracy: 0.3213\n",
            "Epoch 54/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 3.0949 - accuracy: 0.3745 - val_loss: 4.2777 - val_accuracy: 0.3206\n",
            "Epoch 55/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 3.0775 - accuracy: 0.3737 - val_loss: 4.2755 - val_accuracy: 0.3211\n",
            "Epoch 56/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 3.0723 - accuracy: 0.3792 - val_loss: 4.2937 - val_accuracy: 0.3241\n",
            "Epoch 57/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 3.0527 - accuracy: 0.3795 - val_loss: 4.2998 - val_accuracy: 0.3224\n",
            "Epoch 58/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 3.0355 - accuracy: 0.3838 - val_loss: 4.3144 - val_accuracy: 0.3224\n",
            "Epoch 59/100\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 3.0177 - accuracy: 0.3828 - val_loss: 4.3299 - val_accuracy: 0.3222\n",
            "Epoch 60/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 3.0072 - accuracy: 0.3858 - val_loss: 4.3414 - val_accuracy: 0.3231\n",
            "Epoch 61/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.9912 - accuracy: 0.3892 - val_loss: 4.3420 - val_accuracy: 0.3233\n",
            "Epoch 62/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 2.9857 - accuracy: 0.3899 - val_loss: 4.3614 - val_accuracy: 0.3210\n",
            "Epoch 63/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 2.9663 - accuracy: 0.3898 - val_loss: 4.3708 - val_accuracy: 0.3211\n",
            "Epoch 64/100\n",
            "22/22 [==============================] - 5s 220ms/step - loss: 2.9574 - accuracy: 0.3926 - val_loss: 4.3820 - val_accuracy: 0.3221\n",
            "Epoch 65/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 2.9431 - accuracy: 0.3957 - val_loss: 4.3888 - val_accuracy: 0.3208\n",
            "Epoch 66/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 2.9192 - accuracy: 0.3993 - val_loss: 4.4159 - val_accuracy: 0.3221\n",
            "Epoch 67/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 2.9208 - accuracy: 0.3968 - val_loss: 4.4244 - val_accuracy: 0.3191\n",
            "Epoch 68/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.9056 - accuracy: 0.4016 - val_loss: 4.4363 - val_accuracy: 0.3197\n",
            "Epoch 69/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 2.8921 - accuracy: 0.4008 - val_loss: 4.4560 - val_accuracy: 0.3197\n",
            "Epoch 70/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 2.8868 - accuracy: 0.3981 - val_loss: 4.4723 - val_accuracy: 0.3204\n",
            "Epoch 71/100\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 2.8720 - accuracy: 0.4043 - val_loss: 4.4730 - val_accuracy: 0.3210\n",
            "Epoch 72/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.8567 - accuracy: 0.4056 - val_loss: 4.4959 - val_accuracy: 0.3215\n",
            "Epoch 73/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 2.8289 - accuracy: 0.4118 - val_loss: 4.5150 - val_accuracy: 0.3213\n",
            "Epoch 74/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.8330 - accuracy: 0.4141 - val_loss: 4.5244 - val_accuracy: 0.3224\n",
            "Epoch 75/100\n",
            "22/22 [==============================] - 5s 225ms/step - loss: 2.8213 - accuracy: 0.4140 - val_loss: 4.5379 - val_accuracy: 0.3224\n",
            "Epoch 76/100\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 2.7976 - accuracy: 0.4148 - val_loss: 4.5518 - val_accuracy: 0.3228\n",
            "Epoch 77/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.8060 - accuracy: 0.4128 - val_loss: 4.5680 - val_accuracy: 0.3215\n",
            "Epoch 78/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.7815 - accuracy: 0.4151 - val_loss: 4.5814 - val_accuracy: 0.3204\n",
            "Epoch 79/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 2.7793 - accuracy: 0.4162 - val_loss: 4.5909 - val_accuracy: 0.3210\n",
            "Epoch 80/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.7619 - accuracy: 0.4183 - val_loss: 4.6160 - val_accuracy: 0.3213\n",
            "Epoch 81/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 2.7480 - accuracy: 0.4229 - val_loss: 4.6286 - val_accuracy: 0.3215\n",
            "Epoch 82/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.7419 - accuracy: 0.4202 - val_loss: 4.6344 - val_accuracy: 0.3226\n",
            "Epoch 83/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.7409 - accuracy: 0.4194 - val_loss: 4.6619 - val_accuracy: 0.3217\n",
            "Epoch 84/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.7192 - accuracy: 0.4242 - val_loss: 4.6611 - val_accuracy: 0.3202\n",
            "Epoch 85/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 2.7212 - accuracy: 0.4277 - val_loss: 4.6769 - val_accuracy: 0.3211\n",
            "Epoch 86/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.7030 - accuracy: 0.4263 - val_loss: 4.7003 - val_accuracy: 0.3233\n",
            "Epoch 87/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 2.6902 - accuracy: 0.4290 - val_loss: 4.7194 - val_accuracy: 0.3191\n",
            "Epoch 88/100\n",
            "22/22 [==============================] - 5s 221ms/step - loss: 2.6916 - accuracy: 0.4295 - val_loss: 4.7333 - val_accuracy: 0.3219\n",
            "Epoch 89/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 2.6639 - accuracy: 0.4328 - val_loss: 4.7630 - val_accuracy: 0.3213\n",
            "Epoch 90/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.6579 - accuracy: 0.4346 - val_loss: 4.7613 - val_accuracy: 0.3199\n",
            "Epoch 91/100\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 2.6507 - accuracy: 0.4319 - val_loss: 4.7855 - val_accuracy: 0.3197\n",
            "Epoch 92/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.6447 - accuracy: 0.4367 - val_loss: 4.7953 - val_accuracy: 0.3208\n",
            "Epoch 93/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.6406 - accuracy: 0.4354 - val_loss: 4.8171 - val_accuracy: 0.3231\n",
            "Epoch 94/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.6420 - accuracy: 0.4341 - val_loss: 4.8490 - val_accuracy: 0.3206\n",
            "Epoch 95/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.6100 - accuracy: 0.4408 - val_loss: 4.8594 - val_accuracy: 0.3195\n",
            "Epoch 96/100\n",
            "22/22 [==============================] - 5s 225ms/step - loss: 2.6141 - accuracy: 0.4405 - val_loss: 4.8665 - val_accuracy: 0.3201\n",
            "Epoch 97/100\n",
            "22/22 [==============================] - 5s 223ms/step - loss: 2.5985 - accuracy: 0.4426 - val_loss: 4.8914 - val_accuracy: 0.3181\n",
            "Epoch 98/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 2.5923 - accuracy: 0.4415 - val_loss: 4.8944 - val_accuracy: 0.3211\n",
            "Epoch 99/100\n",
            "22/22 [==============================] - 5s 224ms/step - loss: 2.5887 - accuracy: 0.4400 - val_loss: 4.9191 - val_accuracy: 0.3210\n",
            "Epoch 100/100\n",
            "22/22 [==============================] - 5s 222ms/step - loss: 2.5806 - accuracy: 0.4404 - val_loss: 4.9402 - val_accuracy: 0.3201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC6Yr_HdRsp1"
      },
      "source": [
        "学習は結構時間がかかるので、せっかくだし保存しておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwmKFW3a81-d",
        "outputId": "38a849d5-82e6-472a-edc7-d41d97ae5df0"
      },
      "source": [
        "model.save(\"my_model\")"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: my_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnM9Dnd4RxYZ"
      },
      "source": [
        "保存したものを使いたくなった時はロードします"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUy6bbshR9sq"
      },
      "source": [
        "model = tf.keras.models.load_model(\"my_model\")"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTj8rBLfSJ7q"
      },
      "source": [
        "実際にテキストを入れてpredictを行いたいところですが、テキストではなくonehotベクトルのデータを入れないとpredictしてくれないので、テキストをonehotベクトルに変換する関数を作ります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaYMnKBN4e1t",
        "outputId": "8b4e50d4-ab19-4308-fbc4-c45e4c6350db"
      },
      "source": [
        "def text2onehot(text_data,size=-1):\n",
        "  parsed_text = tagger.parse(text_data)\n",
        "  parsed_lines = parsed_text.split(\"\\n\")\n",
        "  words=[]\n",
        "  words.append(0)\n",
        "  for line in parsed_lines:\n",
        "    word=line.split(\"\\t\")\n",
        "    if word[0]=='EOS':\n",
        "      break\n",
        "    try:\n",
        "      words.append(word2id[word[0]])\n",
        "    except:\n",
        "      words.append(0)\n",
        "    if word[0]==\"。\":\n",
        "      words.append(0)\n",
        "  data=one_hot_encode(words,size)\n",
        "  return data\n",
        "start=text2onehot(\"ぼくが６つ\",2019)\n",
        "x_test=[]\n",
        "x_test.append(start)\n",
        "print(np.array(x_test).shape)\n",
        "predictions = model.predict(x_test)\n",
        "print(predictions)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 5, 2019)\n",
            "[[1.1311749e-04 3.0126655e-06 7.5805507e-04 ... 1.1883900e-05\n",
            "  3.9733976e-08 5.0571103e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKSU6mU9Sb5r"
      },
      "source": [
        "無事predictできました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvd9dKtUSbwF"
      },
      "source": [
        "これでラストです！  \n",
        "まず4から11行目の所で、与えられたテキストをpredictに入れられる形に直します。  \n",
        "具体的にはonehotベクトルが５つ並んだ形の２次元リストvecです。  \n",
        "その後はx_test=[vec]としてpredictを行い、結果から次の単語のidであるnext_idを決定、\n",
        "そのidに対応するonehotベクトルを生成してvecの末尾に加え、vecの先頭を削除し、\n",
        "for文の初めに戻る、というのを繰り返します。これで初めの５単語から次々に\n",
        "次の単語を推測して文を作っていくことができます。  \n",
        "next_idの決定方法ですが、argmaxで普通に最大値の引数を取ってくる方法をとると、ある５つの単語に対して常に同じ単語を返すことになってしまい、一度「ループ」にはまってしまうとずっと同じ分を繰り返してい仕舞います。（そうでなくても同じ入力に対し常に同じ出力というのは面白くない）  \n",
        "そこで、randomによって乱数を生成し、次の単語が確率的に決まるようにしています。  \n",
        "例)  \n",
        "predictの結果が[0.1, 0.05, 0.2, 0.6, 0.05]のとき、内側のfor文のvalの値は、  \n",
        "0.1->0.15->0.35->0.95->1.00と増えていきます。\n",
        "このとき、「valの値が初めて乱数rand以上になったときのid」をnext_idとして採用することにします。例えばrandが0.3なら、next_id=2となります。こうすれば、確率0.6でnext_id=3となり、確率0.05でnext_id=4となる、というようにpredictの結果をそのまま確率として利用することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "joqtmIGt_veE",
        "outputId": "985541b4-96d5-4833-8246-4ef99125569b"
      },
      "source": [
        "def make_sentence(start_text,length=10,modelsize=2019,window=5):\n",
        "  res=start_text\n",
        "  vec=text2onehot(start_text,modelsize)\n",
        "  if len(vec)<window:\n",
        "    for i in range(window-len(vec)):\n",
        "      one_hot = np.zeros(modelsize, dtype = int)\n",
        "      one_hot[0]=1\n",
        "      one_hot_list=one_hot.tolist()\n",
        "      vec.insert(0,one_hot_list)\n",
        "  else:\n",
        "    vec=vec[:5]\n",
        "  for i in range(length):\n",
        "    x_test=[]\n",
        "    x_test.append(vec)\n",
        "    predictions = model.predict(x_test)\n",
        "    #next_id=np.argmax(predictions[0])\n",
        "    rand=random.random()\n",
        "    val=0\n",
        "    next_id=modelsize-1\n",
        "    for i in range(modelsize):\n",
        "      val+=predictions[0][i]\n",
        "      if(rand<=val):\n",
        "        next_id=i\n",
        "        break\n",
        "    res+=id2word[next_id]\n",
        "    one_hot = np.zeros(modelsize, dtype = int)\n",
        "    one_hot[next_id]=1\n",
        "    one_hot_list=one_hot.tolist()\n",
        "    vec.append(one_hot_list)\n",
        "    vec.pop(0)\n",
        "  return res\n",
        "make_sentence(\"あしたはきっと\",50)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'あしたはきっとかんだった。「さばくをふしぎはていねいに王子くん。王子くんは２にんも、ほんとは90１らの、しんじなくもんけど、王子くんはいいよ。」と王子くんがとっても'"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JisC4e7hVH3h"
      },
      "source": [
        "結果としては微妙ですね・・・。まあ、モデルも浅いですしword2vecでやるべきいくつかの前処理も難しそうなものはすべて飛ばしてしまったので仕方ありません。精度の改善は今後の課題として、今回はこのあたりにしておきましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chEly3Bwb2TQ"
      },
      "source": [
        "###参考文献\n",
        "「Python の NumPy 配列でのワンホットエンコーディング」https://www.delftstack.com/ja/howto/numpy/one-hot-encoding-numpy/\n",
        "「あのときの王子くん」https://www.aozora.gr.jp/cards/001265/files/46817_24670.html"
      ]
    }
  ]
}